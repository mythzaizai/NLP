{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\r\n",
    "from opencc import OpenCC\r\n",
    "import jieba\r\n",
    "import re\r\n",
    "from gensim.models import word2vec\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "r = '[）\\（\\：\\·\\，\\。\\“ \\”\\?\\？\\」\\「\\……\\、\\《\\》\\；\\)\\(]'\r\n",
    "file = ['AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK','AL']\r\n",
    "cc = OpenCC('s2t')\r\n",
    "\r\n",
    "def open_wiki():\r\n",
    "    \r\n",
    "    result =[]\r\n",
    "\r\n",
    "    for a in file[0:4]:\r\n",
    "        for i in range(100):\r\n",
    "            for line in open('wiki_zh/{}/wiki_{}'.format(a,str(i).zfill(2))):\r\n",
    "                data = json.loads(line)\r\n",
    "                value = re.sub(r,'',data['text'])\r\n",
    "                result.append(value)\r\n",
    "\r\n",
    "    for a in file[5:8]:\r\n",
    "        for i in range(100):\r\n",
    "            for line in open('wiki_zh/{}/wiki_{}'.format(a,str(i).zfill(2))): \r\n",
    "                data = json.loads(line)\r\n",
    "                value = re.sub(r,'',data['text'])\r\n",
    "                result.append(value)\r\n",
    "\r\n",
    "    for a in file[9:11]:\r\n",
    "        for i in range(100):\r\n",
    "            for line in open('wiki_zh/{}/wiki_{}'.format(a,str(i).zfill(2))):\r\n",
    "                data = json.loads(line)\r\n",
    "                value = re.sub(r,'',data['text'])\r\n",
    "                result.append(value)\r\n",
    "\r\n",
    "    for i in range(74):\r\n",
    "        for line in open('wiki_zh/{}/wiki_{}'.format('AM',str(i).zfill(2))):\r\n",
    "            data = json.loads(line)\r\n",
    "            value = re.sub(r,'',data['text'])\r\n",
    "            result.append(value)\r\n",
    "            \r\n",
    "    return result\r\n",
    "    \r\n",
    "result = open_wiki()\r\n",
    "\r\n",
    "print(len(result))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_stopword_list():       \r\n",
    "    with open('wiki_zh/cn_stopwords.txt') as f: \r\n",
    "        stopword_list = [word.strip('\\n') for word in f.readlines()]\r\n",
    "    return stopword_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def word2():\r\n",
    "    train_data = word2vec.LineSentence('test.txt')\r\n",
    "\r\n",
    "    sg = 0\r\n",
    "    vector_size = 300\r\n",
    "\r\n",
    "    workers = 4\r\n",
    "    epochs = 5\r\n",
    "\r\n",
    "    model = word2vec.Word2Vec(\r\n",
    "        train_data,\r\n",
    "\r\n",
    "        vector_size=vector_size,\r\n",
    "        workers=workers,\r\n",
    "        epochs=epochs,\r\n",
    "\r\n",
    "        sg=sg,\r\n",
    "    )\r\n",
    "    model.save('word2vec.model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "word2()\r\n",
    "print('訓練成功！')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "8ed4e271d6aa5bdf09e7dd5fc3c50c9ac3100a2a14b14fb9bf6dae731e3cbb94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}