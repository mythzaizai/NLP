{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import re\r\n",
    "import pandas as pd\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "import jieba\r\n",
    "import jieba.analyse\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def cutval(df):\r\n",
    "    name_cut = []\r\n",
    "    for d in df['中文名稱']:\r\n",
    "        ch =re.compile(\"[\\u4e00-\\u9fa5]\")\r\n",
    "        name =  \"\".join(ch.findall(d))\r\n",
    "        name_cut.append(name)\r\n",
    "\r\n",
    "    type_cut = []\r\n",
    "    for d in df['類型']:\r\n",
    "        ch =re.compile(\"[\\u4e00-\\u9fa5]\")\r\n",
    "        seg_word =  \"\".join(ch.findall(d))\r\n",
    "        types = jieba.lcut(seg_word)\r\n",
    "        type_cut.append(types)\r\n",
    "\r\n",
    "    intro_cut = []\r\n",
    "    for d in df['簡介']:\r\n",
    "        intro = jieba.analyse.extract_tags(d,topK=2)\r\n",
    "        intro_cut.append(intro)\r\n",
    "    \r\n",
    "\r\n",
    "    data = {'name':name_cut,'type':type_cut ,'article':intro_cut}\r\n",
    "    df1 = pd.DataFrame(data)\r\n",
    "\r\n",
    "    df1['type'] = df1['type'].apply(lambda x :  str(x)[1:-2].replace(\"'\",\"\").replace(\",\",\"\"))\r\n",
    "    df1['article'] = df1['article'].apply(lambda x :  str(x)[1:-2].replace(\"'\",\"\").replace(\",\",\"\"))\r\n",
    "    df1['key'] = df1['name'].astype(str)+' '+df1['type'].astype(str)+' '+df1['article'].astype(str)\r\n",
    "    return df1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def count(df):\r\n",
    "    vectorizer = CountVectorizer()\r\n",
    "    X = vectorizer.fit_transform(df['key'])\r\n",
    "    tfidf = TfidfTransformer() \r\n",
    "    tf=tfidf.fit_transform(X)\r\n",
    "    word = vectorizer.get_feature_names() \r\n",
    "    \r\n",
    "    return tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def knn(X,Y):\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y['type'].str[0:2], test_size=0.07659)\r\n",
    "    clf=KNeighborsClassifier(n_neighbors=51)\r\n",
    "    clf.fit(X_train,y_train)\r\n",
    "\r\n",
    "    y_pred = clf.predict(X_test)\r\n",
    "    y_test=y_test.values\r\n",
    "\r\n",
    "    print(\"精準度：\",metrics.accuracy_score(y_test, y_pred))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "test_df = pd.read_csv('data.csv')\r\n",
    "test_df = test_df.drop(labels=['Unnamed: 0'],axis='columns')\r\n",
    "\r\n",
    "name_cut = []\r\n",
    "for d in test_df['中文名稱']:\r\n",
    "    ch =re.compile(\"[\\u4e00-\\u9fa5]\")\r\n",
    "    name =  \"\".join(ch.findall(d))\r\n",
    "    name_cut.append(name)\r\n",
    "\r\n",
    "type_cut = []\r\n",
    "for d in test_df['類型']:\r\n",
    "    ch =re.compile(\"[\\u4e00-\\u9fa5]\")\r\n",
    "    seg_word =  \"\".join(ch.findall(d))\r\n",
    "    types = jieba.lcut(seg_word)\r\n",
    "    type_cut.append(types)\r\n",
    "\r\n",
    "intro_cut = []\r\n",
    "for d in test_df['簡介']:\r\n",
    "    intro = jieba.analyse.extract_tags(d,topK=2)\r\n",
    "    intro_cut.append(intro)\r\n",
    "    \r\n",
    "\r\n",
    "data = {'name':name_cut,'type':type_cut ,'article':intro_cut}\r\n",
    "df1 = pd.DataFrame(data)\r\n",
    "\r\n",
    "df1['type'] = df1['type'].apply(lambda x :  str(x)[1:-2].replace(\"'\",\"\").replace(\",\",\"\"))\r\n",
    "df1['article'] = df1['article'].apply(lambda x :  str(x)[1:-2].replace(\"'\",\"\").replace(\",\",\"\"))\r\n",
    "df1['key'] = df1['name'].astype(str)+' '+df1['type'].astype(str)+' '+df1['article'].astype(str)\r\n",
    "\r\n",
    "\r\n",
    "tf = count(df1)\r\n",
    "knn(tf,df1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "精準度： 0.7667844522968198\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}